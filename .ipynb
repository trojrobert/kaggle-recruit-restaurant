{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle recruit restaurant solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains my solution to the [Kaggle Recruit Restaurant Visitor Forecasting](https://www.kaggle.com/c/recruit-restaurant-visitor-forecasting). I went for simplicity and used a single, global, model. I spent most of my time doing feature engineering. I mainly focused on extracting so-called rolling statistics.\n",
    "\n",
    "By itself the output of this notebook scores 0.512 on the private leaderboard, which is enough to be part of the top 25. I then averaged my solution with the [Surprise Me](https://www.kaggle.com/the1owl/surprise-me) public kernel to score 0.507. You could say that I only did half the work. However if the public kernel was not available I would simply have built another model and used it instead. Blending kernels to score has become ubiquitous to do well on Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading\n",
    "\n",
    "For obvious reasons I haven't commited the data files on GitHub. To run this kernel yourself as it is you will have to organise your files in a certain way. All the files provided by Kaggle should be stored in the `data/kaggle` directory. Additionally, the weather data located [here](https://www.kaggle.com/huntermcgushion/rrv-weather-data) has to be kept in the `data/weather` directory.\n",
    "\n",
    "First of all let's load the visit data. I did something very important in the following code block. Instead of taking the visiting data as is, I resampled it by day so that for days where there are no data points the number of visits is 0. This is important for computing rolling features based on time. I also keep track of whether a point was included in the original dataset or was added by the resampling procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>visitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-14</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-16</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-18</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id  visit_date  visitors\n",
       "0  air_ba937bf13d40fb24  2016-01-13        25\n",
       "1  air_ba937bf13d40fb24  2016-01-14        32\n",
       "2  air_ba937bf13d40fb24  2016-01-15        29\n",
       "3  air_ba937bf13d40fb24  2016-01-16        22\n",
       "4  air_ba937bf13d40fb24  2016-01-18         6"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "air_visit = pd.read_csv('data/kaggle/air_visit_data.csv')\n",
    "air_visit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "air_store_id    False\n",
       "visit_date      False\n",
       "visitors        False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "air_visit.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>visitors</th>\n",
       "      <th>was_nil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>35</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-07-02</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-07-03</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-07-04</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-07-05</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id  visit_date  visitors  was_nil\n",
       "0  air_00a91d42b08b08d9  2016-07-01        35    False\n",
       "1  air_00a91d42b08b08d9  2016-07-02         9    False\n",
       "2  air_00a91d42b08b08d9  2016-07-03         0    False\n",
       "3  air_00a91d42b08b08d9  2016-07-04        20    False\n",
       "4  air_00a91d42b08b08d9  2016-07-05        25    False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "air_visit.index = pd.to_datetime(air_visit['visit_date'])\n",
    "air_visit = air_visit.groupby('air_store_id').apply(lambda g: g['visitors'].resample('1d').sum()).reset_index()\n",
    "air_visit['visit_date'] = air_visit['visit_date'].dt.strftime('%Y-%m-%d')\n",
    "air_visit['was_nil'] = air_visit['visitors'].isnull()\n",
    "air_visit['visitors'].fillna(0, inplace=True)\n",
    "\n",
    "air_visit.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's take care of the calendar information. Apart from remaining the column names for practical reasons I added two features indicating if the previous or the next day is a holiday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visit_date</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>prev_day_is_holiday</th>\n",
       "      <th>next_day_is_holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>Friday</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>Monday</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   visit_date day_of_week  is_holiday  prev_day_is_holiday  \\\n",
       "0  2016-01-01      Friday           1                  0.0   \n",
       "1  2016-01-02    Saturday           1                  1.0   \n",
       "2  2016-01-03      Sunday           1                  1.0   \n",
       "3  2016-01-04      Monday           0                  1.0   \n",
       "4  2016-01-05     Tuesday           0                  0.0   \n",
       "\n",
       "   next_day_is_holiday  \n",
       "0                  1.0  \n",
       "1                  1.0  \n",
       "2                  0.0  \n",
       "3                  0.0  \n",
       "4                  0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_info = pd.read_csv('data/kaggle/date_info.csv')\n",
    "date_info.rename(columns={'holiday_flg': 'is_holiday', 'calendar_date': 'visit_date'}, inplace=True)\n",
    "date_info['prev_day_is_holiday'] = date_info['is_holiday'].shift().fillna(0)\n",
    "date_info['next_day_is_holiday'] = date_info['is_holiday'].shift(-1).fillna(0)\n",
    "\n",
    "date_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for the store information I used the preprocessed version coming from the weather data instead of the \"official\" Kaggle version. The reason why is that the preprocessed version contains weather station data important for joining the weather features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>air_genre_name</th>\n",
       "      <th>air_area_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude_str</th>\n",
       "      <th>longitude_str</th>\n",
       "      <th>station_id</th>\n",
       "      <th>station_latitude</th>\n",
       "      <th>station_longitude</th>\n",
       "      <th>station_vincenty</th>\n",
       "      <th>station_great_circle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_0f0cdeee6c9bf3d7</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Hyōgo-ken Kōbe-shi Kumoidōri</td>\n",
       "      <td>34.695124</td>\n",
       "      <td>135.197852</td>\n",
       "      <td>\"34.6951242\"</td>\n",
       "      <td>\"135.1978525\"</td>\n",
       "      <td>hyogo__kobe-kana__koube</td>\n",
       "      <td>34.696667</td>\n",
       "      <td>135.211667</td>\n",
       "      <td>1.277232</td>\n",
       "      <td>1.274882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_7cc17a324ae5c7dc</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Hyōgo-ken Kōbe-shi Kumoidōri</td>\n",
       "      <td>34.695124</td>\n",
       "      <td>135.197852</td>\n",
       "      <td>\"34.6951242\"</td>\n",
       "      <td>\"135.1978525\"</td>\n",
       "      <td>hyogo__kobe-kana__koube</td>\n",
       "      <td>34.696667</td>\n",
       "      <td>135.211667</td>\n",
       "      <td>1.277232</td>\n",
       "      <td>1.274882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_fee8dcf4d619598e</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Hyōgo-ken Kōbe-shi Kumoidōri</td>\n",
       "      <td>34.695124</td>\n",
       "      <td>135.197852</td>\n",
       "      <td>\"34.6951242\"</td>\n",
       "      <td>\"135.1978525\"</td>\n",
       "      <td>hyogo__kobe-kana__koube</td>\n",
       "      <td>34.696667</td>\n",
       "      <td>135.211667</td>\n",
       "      <td>1.277232</td>\n",
       "      <td>1.274882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_a17f0778617c76e2</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Hyōgo-ken Kōbe-shi Kumoidōri</td>\n",
       "      <td>34.695124</td>\n",
       "      <td>135.197852</td>\n",
       "      <td>\"34.6951242\"</td>\n",
       "      <td>\"135.1978525\"</td>\n",
       "      <td>hyogo__kobe-kana__koube</td>\n",
       "      <td>34.696667</td>\n",
       "      <td>135.211667</td>\n",
       "      <td>1.277232</td>\n",
       "      <td>1.274882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_83db5aff8f50478e</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>\"35.6580681\"</td>\n",
       "      <td>\"139.7515992\"</td>\n",
       "      <td>tokyo__tokyo-kana__tonokyo</td>\n",
       "      <td>35.691667</td>\n",
       "      <td>139.750000</td>\n",
       "      <td>3.730672</td>\n",
       "      <td>3.739835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id  air_genre_name                 air_area_name  \\\n",
       "0  air_0f0cdeee6c9bf3d7  Italian/French  Hyōgo-ken Kōbe-shi Kumoidōri   \n",
       "1  air_7cc17a324ae5c7dc  Italian/French  Hyōgo-ken Kōbe-shi Kumoidōri   \n",
       "2  air_fee8dcf4d619598e  Italian/French  Hyōgo-ken Kōbe-shi Kumoidōri   \n",
       "3  air_a17f0778617c76e2  Italian/French  Hyōgo-ken Kōbe-shi Kumoidōri   \n",
       "4  air_83db5aff8f50478e  Italian/French  Tōkyō-to Minato-ku Shibakōen   \n",
       "\n",
       "    latitude   longitude  latitude_str  longitude_str  \\\n",
       "0  34.695124  135.197852  \"34.6951242\"  \"135.1978525\"   \n",
       "1  34.695124  135.197852  \"34.6951242\"  \"135.1978525\"   \n",
       "2  34.695124  135.197852  \"34.6951242\"  \"135.1978525\"   \n",
       "3  34.695124  135.197852  \"34.6951242\"  \"135.1978525\"   \n",
       "4  35.658068  139.751599  \"35.6580681\"  \"139.7515992\"   \n",
       "\n",
       "                   station_id  station_latitude  station_longitude  \\\n",
       "0     hyogo__kobe-kana__koube         34.696667         135.211667   \n",
       "1     hyogo__kobe-kana__koube         34.696667         135.211667   \n",
       "2     hyogo__kobe-kana__koube         34.696667         135.211667   \n",
       "3     hyogo__kobe-kana__koube         34.696667         135.211667   \n",
       "4  tokyo__tokyo-kana__tonokyo         35.691667         139.750000   \n",
       "\n",
       "   station_vincenty  station_great_circle  \n",
       "0          1.277232              1.274882  \n",
       "1          1.277232              1.274882  \n",
       "2          1.277232              1.274882  \n",
       "3          1.277232              1.274882  \n",
       "4          3.730672              3.739835  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "air_store_info = pd.read_csv('data/weather/air_store_info_with_nearest_active_station.csv')\n",
    "\n",
    "air_store_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's handle the test set. Because of the timeseries nature of the competition the test split is implicitely contained in the example submission. We can extract the store id and the date from the `id` column. I also keep track of the order of the test because I'm a maniac and I want to make sure my submission is sorted in the right order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>visitors</th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>is_test</th>\n",
       "      <th>test_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2017-04-24</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2017-04-25</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2017-04-26</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2017-04-27</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id  visitors          air_store_id  \\\n",
       "0  air_00a91d42b08b08d9_2017-04-23       NaN  air_00a91d42b08b08d9   \n",
       "1  air_00a91d42b08b08d9_2017-04-24       NaN  air_00a91d42b08b08d9   \n",
       "2  air_00a91d42b08b08d9_2017-04-25       NaN  air_00a91d42b08b08d9   \n",
       "3  air_00a91d42b08b08d9_2017-04-26       NaN  air_00a91d42b08b08d9   \n",
       "4  air_00a91d42b08b08d9_2017-04-27       NaN  air_00a91d42b08b08d9   \n",
       "\n",
       "   visit_date  is_test  test_number  \n",
       "0  2017-04-23     True            0  \n",
       "1  2017-04-24     True            1  \n",
       "2  2017-04-25     True            2  \n",
       "3  2017-04-26     True            3  \n",
       "4  2017-04-27     True            4  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "submission = pd.read_csv('data/kaggle/sample_submission.csv')\n",
    "submission['air_store_id'] = submission['id'].str.slice(0, 20)\n",
    "submission['visit_date'] = submission['id'].str.slice(21)\n",
    "submission['is_test'] = True\n",
    "submission['visitors'] = np.nan\n",
    "submission['test_number'] = range(len(submission))\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the training set and the test set in same format we can merge them together. Merging the training and test sets is a good idea to extract features in one go. Let's also merge the full dataset with the calendar information and the store information extracted previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>visitors</th>\n",
       "      <th>was_nil</th>\n",
       "      <th>is_test</th>\n",
       "      <th>test_number</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>prev_day_is_holiday</th>\n",
       "      <th>next_day_is_holiday</th>\n",
       "      <th>...</th>\n",
       "      <th>air_area_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude_str</th>\n",
       "      <th>longitude_str</th>\n",
       "      <th>station_id</th>\n",
       "      <th>station_latitude</th>\n",
       "      <th>station_longitude</th>\n",
       "      <th>station_vincenty</th>\n",
       "      <th>station_great_circle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>35.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Tōkyō-to Chiyoda-ku Kudanminami</td>\n",
       "      <td>35.694003</td>\n",
       "      <td>139.753595</td>\n",
       "      <td>\"35.6940027\"</td>\n",
       "      <td>\"139.7535951\"</td>\n",
       "      <td>tokyo__tokyo-kana__tonokyo</td>\n",
       "      <td>35.691667</td>\n",
       "      <td>139.75</td>\n",
       "      <td>0.416011</td>\n",
       "      <td>0.415906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-07-02</td>\n",
       "      <td>9.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Tōkyō-to Chiyoda-ku Kudanminami</td>\n",
       "      <td>35.694003</td>\n",
       "      <td>139.753595</td>\n",
       "      <td>\"35.6940027\"</td>\n",
       "      <td>\"139.7535951\"</td>\n",
       "      <td>tokyo__tokyo-kana__tonokyo</td>\n",
       "      <td>35.691667</td>\n",
       "      <td>139.75</td>\n",
       "      <td>0.416011</td>\n",
       "      <td>0.415906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-07-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Tōkyō-to Chiyoda-ku Kudanminami</td>\n",
       "      <td>35.694003</td>\n",
       "      <td>139.753595</td>\n",
       "      <td>\"35.6940027\"</td>\n",
       "      <td>\"139.7535951\"</td>\n",
       "      <td>tokyo__tokyo-kana__tonokyo</td>\n",
       "      <td>35.691667</td>\n",
       "      <td>139.75</td>\n",
       "      <td>0.416011</td>\n",
       "      <td>0.415906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-07-04</td>\n",
       "      <td>20.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Monday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Tōkyō-to Chiyoda-ku Kudanminami</td>\n",
       "      <td>35.694003</td>\n",
       "      <td>139.753595</td>\n",
       "      <td>\"35.6940027\"</td>\n",
       "      <td>\"139.7535951\"</td>\n",
       "      <td>tokyo__tokyo-kana__tonokyo</td>\n",
       "      <td>35.691667</td>\n",
       "      <td>139.75</td>\n",
       "      <td>0.416011</td>\n",
       "      <td>0.415906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-07-05</td>\n",
       "      <td>25.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Tōkyō-to Chiyoda-ku Kudanminami</td>\n",
       "      <td>35.694003</td>\n",
       "      <td>139.753595</td>\n",
       "      <td>\"35.6940027\"</td>\n",
       "      <td>\"139.7535951\"</td>\n",
       "      <td>tokyo__tokyo-kana__tonokyo</td>\n",
       "      <td>35.691667</td>\n",
       "      <td>139.75</td>\n",
       "      <td>0.416011</td>\n",
       "      <td>0.415906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id  visit_date  visitors was_nil  is_test  test_number  \\\n",
       "0  air_00a91d42b08b08d9  2016-07-01      35.0   False    False          NaN   \n",
       "1  air_00a91d42b08b08d9  2016-07-02       9.0   False    False          NaN   \n",
       "2  air_00a91d42b08b08d9  2016-07-03       0.0   False    False          NaN   \n",
       "3  air_00a91d42b08b08d9  2016-07-04      20.0   False    False          NaN   \n",
       "4  air_00a91d42b08b08d9  2016-07-05      25.0   False    False          NaN   \n",
       "\n",
       "  day_of_week  is_holiday  prev_day_is_holiday  next_day_is_holiday  ...  \\\n",
       "0      Friday           0                  0.0                  0.0  ...   \n",
       "1    Saturday           0                  0.0                  0.0  ...   \n",
       "2      Sunday           0                  0.0                  0.0  ...   \n",
       "3      Monday           0                  0.0                  0.0  ...   \n",
       "4     Tuesday           0                  0.0                  0.0  ...   \n",
       "\n",
       "                     air_area_name   latitude   longitude  latitude_str  \\\n",
       "0  Tōkyō-to Chiyoda-ku Kudanminami  35.694003  139.753595  \"35.6940027\"   \n",
       "1  Tōkyō-to Chiyoda-ku Kudanminami  35.694003  139.753595  \"35.6940027\"   \n",
       "2  Tōkyō-to Chiyoda-ku Kudanminami  35.694003  139.753595  \"35.6940027\"   \n",
       "3  Tōkyō-to Chiyoda-ku Kudanminami  35.694003  139.753595  \"35.6940027\"   \n",
       "4  Tōkyō-to Chiyoda-ku Kudanminami  35.694003  139.753595  \"35.6940027\"   \n",
       "\n",
       "   longitude_str                  station_id station_latitude  \\\n",
       "0  \"139.7535951\"  tokyo__tokyo-kana__tonokyo        35.691667   \n",
       "1  \"139.7535951\"  tokyo__tokyo-kana__tonokyo        35.691667   \n",
       "2  \"139.7535951\"  tokyo__tokyo-kana__tonokyo        35.691667   \n",
       "3  \"139.7535951\"  tokyo__tokyo-kana__tonokyo        35.691667   \n",
       "4  \"139.7535951\"  tokyo__tokyo-kana__tonokyo        35.691667   \n",
       "\n",
       "   station_longitude  station_vincenty  station_great_circle  \n",
       "0             139.75          0.416011              0.415906  \n",
       "1             139.75          0.416011              0.415906  \n",
       "2             139.75          0.416011              0.415906  \n",
       "3             139.75          0.416011              0.415906  \n",
       "4             139.75          0.416011              0.415906  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat((air_visit, submission.drop('id', axis='columns')))\n",
    "data['is_test'].fillna(False, inplace=True)\n",
    "data = pd.merge(left=data, right=date_info, on='visit_date', how='left')\n",
    "data = pd.merge(left=data, right=air_store_info, on='air_store_id', how='left')\n",
    "data['visitors'] = data['visitors'].astype(float)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the messy part. The weather data is stored in individual files, one file for weather station. We also know each restaurant's closest weather station. To make things even more enjoyable there are some missing values for each weather station. Let's first start by loading the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visit_date</th>\n",
       "      <th>avg_temperature</th>\n",
       "      <th>high_temperature</th>\n",
       "      <th>low_temperature</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>hours_sunlight</th>\n",
       "      <th>solar_radiation</th>\n",
       "      <th>deepest_snowfall</th>\n",
       "      <th>total_snowfall</th>\n",
       "      <th>avg_wind_speed</th>\n",
       "      <th>avg_vapor_pressure</th>\n",
       "      <th>avg_local_pressure</th>\n",
       "      <th>avg_humidity</th>\n",
       "      <th>avg_sea_pressure</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>station_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aichi__ai-xi-kana__isaai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>4.7</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aichi__ai-xi-kana__isaai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aichi__ai-xi-kana__isaai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>8.8</td>\n",
       "      <td>14.7</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aichi__ai-xi-kana__isaai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>8.9</td>\n",
       "      <td>14.1</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aichi__ai-xi-kana__isaai</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   visit_date  avg_temperature  high_temperature  low_temperature  \\\n",
       "0  2016-01-01              6.0              11.0              0.7   \n",
       "1  2016-01-02              4.7              10.5              0.0   \n",
       "2  2016-01-03              7.0              13.8              1.9   \n",
       "3  2016-01-04              8.8              14.7              2.7   \n",
       "4  2016-01-05              8.9              14.1              3.4   \n",
       "\n",
       "   precipitation  hours_sunlight  solar_radiation  deepest_snowfall  \\\n",
       "0            0.0             9.1              NaN               NaN   \n",
       "1            0.0             6.8              NaN               NaN   \n",
       "2            0.0             8.6              NaN               NaN   \n",
       "3            0.0             5.3              NaN               NaN   \n",
       "4            0.0             4.5              NaN               NaN   \n",
       "\n",
       "   total_snowfall  avg_wind_speed  avg_vapor_pressure  avg_local_pressure  \\\n",
       "0             NaN             2.9                 NaN                 NaN   \n",
       "1             NaN             1.4                 NaN                 NaN   \n",
       "2             NaN             1.4                 NaN                 NaN   \n",
       "3             NaN             2.2                 NaN                 NaN   \n",
       "4             NaN             2.7                 NaN                 NaN   \n",
       "\n",
       "   avg_humidity  avg_sea_pressure  cloud_cover                station_id  \n",
       "0           NaN               NaN          NaN  aichi__ai-xi-kana__isaai  \n",
       "1           NaN               NaN          NaN  aichi__ai-xi-kana__isaai  \n",
       "2           NaN               NaN          NaN  aichi__ai-xi-kana__isaai  \n",
       "3           NaN               NaN          NaN  aichi__ai-xi-kana__isaai  \n",
       "4           NaN               NaN          NaN  aichi__ai-xi-kana__isaai  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "weather_dfs = []\n",
    "\n",
    "for path in glob.glob('data/weather/1-1-16_5-31-17_Weather/1-1-16_5-31-17_Weather/*.csv'):\n",
    "    weather_df = pd.read_csv(path)\n",
    "    weather_df['station_id'] = path.split('\\\\')[-1].rstrip('.csv')\n",
    "    weather_dfs.append(weather_df)\n",
    "\n",
    "weather = pd.concat(weather_dfs, axis='rows')\n",
    "weather.rename(columns={'calendar_date': 'visit_date'}, inplace=True)\n",
    "\n",
    "weather.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After some testing and browsing the Kaggle forums it seemed only worthwhile to use the precipitation and the temperature features. I handled the missing values by replacing them with the global daily average. If I wasn't so lazy I would have taken the average of the $n$ closest stations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visit_date</th>\n",
       "      <th>avg_temperature</th>\n",
       "      <th>precipitation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>10.2</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>8.8</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   visit_date  avg_temperature  precipitation\n",
       "0  2016-01-01              5.7            0.0\n",
       "1  2016-01-02             10.2            0.5\n",
       "2  2016-01-03             11.2            0.0\n",
       "3  2016-01-04              9.4            0.0\n",
       "4  2016-01-05              8.8            1.5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means = weather.groupby('visit_date')[['avg_temperature', 'precipitation']].mean().reset_index()\n",
    "means.rename(columns={'avg_temperature': 'global_avg_temperature', 'precipitation': 'global_precipitation'}, inplace=True)\n",
    "weather = pd.merge(left=weather, right=means, on='visit_date', how='left')\n",
    "weather['avg_temperature'].fillna(weather['global_avg_temperature'], inplace=True)\n",
    "weather['precipitation'].fillna(weather['global_precipitation'], inplace=True)\n",
    "\n",
    "weather[['visit_date', 'avg_temperature', 'precipitation']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let's tidy the final dataframe before extracting some juicy features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>is_test</th>\n",
       "      <th>test_number</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>visitors</th>\n",
       "      <th>was_nil</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>prev_day_is_holiday</th>\n",
       "      <th>next_day_is_holiday</th>\n",
       "      <th>air_genre_name</th>\n",
       "      <th>air_area_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>station_id</th>\n",
       "      <th>station_latitude</th>\n",
       "      <th>station_longitude</th>\n",
       "      <th>station_vincenty</th>\n",
       "      <th>station_great_circle</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visit_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-07-01</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>35.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Tōkyō-to Chiyoda-ku Kudanminami</td>\n",
       "      <td>35.694003</td>\n",
       "      <td>139.753595</td>\n",
       "      <td>tokyo__tokyo-kana__tonokyo</td>\n",
       "      <td>35.691667</td>\n",
       "      <td>139.75</td>\n",
       "      <td>0.416011</td>\n",
       "      <td>0.415906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-02</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-07-02</td>\n",
       "      <td>9.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Tōkyō-to Chiyoda-ku Kudanminami</td>\n",
       "      <td>35.694003</td>\n",
       "      <td>139.753595</td>\n",
       "      <td>tokyo__tokyo-kana__tonokyo</td>\n",
       "      <td>35.691667</td>\n",
       "      <td>139.75</td>\n",
       "      <td>0.416011</td>\n",
       "      <td>0.415906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-03</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-07-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Tōkyō-to Chiyoda-ku Kudanminami</td>\n",
       "      <td>35.694003</td>\n",
       "      <td>139.753595</td>\n",
       "      <td>tokyo__tokyo-kana__tonokyo</td>\n",
       "      <td>35.691667</td>\n",
       "      <td>139.75</td>\n",
       "      <td>0.416011</td>\n",
       "      <td>0.415906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-04</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-07-04</td>\n",
       "      <td>20.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Monday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Tōkyō-to Chiyoda-ku Kudanminami</td>\n",
       "      <td>35.694003</td>\n",
       "      <td>139.753595</td>\n",
       "      <td>tokyo__tokyo-kana__tonokyo</td>\n",
       "      <td>35.691667</td>\n",
       "      <td>139.75</td>\n",
       "      <td>0.416011</td>\n",
       "      <td>0.415906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-05</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-07-05</td>\n",
       "      <td>25.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Tōkyō-to Chiyoda-ku Kudanminami</td>\n",
       "      <td>35.694003</td>\n",
       "      <td>139.753595</td>\n",
       "      <td>tokyo__tokyo-kana__tonokyo</td>\n",
       "      <td>35.691667</td>\n",
       "      <td>139.75</td>\n",
       "      <td>0.416011</td>\n",
       "      <td>0.415906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    air_store_id  is_test  test_number visit_date  visitors  \\\n",
       "visit_date                                                                    \n",
       "2016-07-01  air_00a91d42b08b08d9    False          NaN 2016-07-01      35.0   \n",
       "2016-07-02  air_00a91d42b08b08d9    False          NaN 2016-07-02       9.0   \n",
       "2016-07-03  air_00a91d42b08b08d9    False          NaN 2016-07-03       0.0   \n",
       "2016-07-04  air_00a91d42b08b08d9    False          NaN 2016-07-04      20.0   \n",
       "2016-07-05  air_00a91d42b08b08d9    False          NaN 2016-07-05      25.0   \n",
       "\n",
       "           was_nil day_of_week  is_holiday  prev_day_is_holiday  \\\n",
       "visit_date                                                        \n",
       "2016-07-01   False      Friday           0                  0.0   \n",
       "2016-07-02   False    Saturday           0                  0.0   \n",
       "2016-07-03    True      Sunday           0                  0.0   \n",
       "2016-07-04   False      Monday           0                  0.0   \n",
       "2016-07-05   False     Tuesday           0                  0.0   \n",
       "\n",
       "            next_day_is_holiday  air_genre_name  \\\n",
       "visit_date                                        \n",
       "2016-07-01                  0.0  Italian/French   \n",
       "2016-07-02                  0.0  Italian/French   \n",
       "2016-07-03                  0.0  Italian/French   \n",
       "2016-07-04                  0.0  Italian/French   \n",
       "2016-07-05                  0.0  Italian/French   \n",
       "\n",
       "                              air_area_name   latitude   longitude  \\\n",
       "visit_date                                                           \n",
       "2016-07-01  Tōkyō-to Chiyoda-ku Kudanminami  35.694003  139.753595   \n",
       "2016-07-02  Tōkyō-to Chiyoda-ku Kudanminami  35.694003  139.753595   \n",
       "2016-07-03  Tōkyō-to Chiyoda-ku Kudanminami  35.694003  139.753595   \n",
       "2016-07-04  Tōkyō-to Chiyoda-ku Kudanminami  35.694003  139.753595   \n",
       "2016-07-05  Tōkyō-to Chiyoda-ku Kudanminami  35.694003  139.753595   \n",
       "\n",
       "                            station_id  station_latitude  station_longitude  \\\n",
       "visit_date                                                                    \n",
       "2016-07-01  tokyo__tokyo-kana__tonokyo         35.691667             139.75   \n",
       "2016-07-02  tokyo__tokyo-kana__tonokyo         35.691667             139.75   \n",
       "2016-07-03  tokyo__tokyo-kana__tonokyo         35.691667             139.75   \n",
       "2016-07-04  tokyo__tokyo-kana__tonokyo         35.691667             139.75   \n",
       "2016-07-05  tokyo__tokyo-kana__tonokyo         35.691667             139.75   \n",
       "\n",
       "            station_vincenty  station_great_circle  \n",
       "visit_date                                          \n",
       "2016-07-01          0.416011              0.415906  \n",
       "2016-07-02          0.416011              0.415906  \n",
       "2016-07-03          0.416011              0.415906  \n",
       "2016-07-04          0.416011              0.415906  \n",
       "2016-07-05          0.416011              0.415906  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['visit_date'] = pd.to_datetime(data['visit_date'])\n",
    "data.index = data['visit_date']\n",
    "data.sort_values(['air_store_id', 'visit_date'], inplace=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a few iterations I noticed that there were many outliers in the datasets. For example the number of visits around New Year is clearly not representative of the rest of the year. In this case outliers are values that are extremely high (there are no negative values in the dataset, duh). I didn't go out of my way and did something really simple. I simply defined outliers as values that were outside of a confidence interval, supposing that the visits follow a normal distribution per restaurant. The 2.4 in the following code block is simply a high quantile of the normal distribution. You could just as well have used 1.96 if you wanted to choose the top 5% of values as outliers. Once I have detected outliers, I created a new variable called `visitors_capped` where the outlier values are replaced with the maximum of the non-outlier values. You can read more about my method (and others) by checking out [this thread](https://www.kaggle.com/c/recruit-restaurant-visitor-forecasting/discussion/46939)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>is_test</th>\n",
       "      <th>test_number</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>visitors</th>\n",
       "      <th>was_nil</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>prev_day_is_holiday</th>\n",
       "      <th>next_day_is_holiday</th>\n",
       "      <th>...</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>station_id</th>\n",
       "      <th>station_latitude</th>\n",
       "      <th>station_longitude</th>\n",
       "      <th>station_vincenty</th>\n",
       "      <th>station_great_circle</th>\n",
       "      <th>is_outlier</th>\n",
       "      <th>visitors_capped</th>\n",
       "      <th>visitors_capped_log1p</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visit_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-07-01</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>35.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35.694003</td>\n",
       "      <td>139.753595</td>\n",
       "      <td>tokyo__tokyo-kana__tonokyo</td>\n",
       "      <td>35.691667</td>\n",
       "      <td>139.75</td>\n",
       "      <td>0.416011</td>\n",
       "      <td>0.415906</td>\n",
       "      <td>False</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3.583519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-02</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-07-02</td>\n",
       "      <td>9.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35.694003</td>\n",
       "      <td>139.753595</td>\n",
       "      <td>tokyo__tokyo-kana__tonokyo</td>\n",
       "      <td>35.691667</td>\n",
       "      <td>139.75</td>\n",
       "      <td>0.416011</td>\n",
       "      <td>0.415906</td>\n",
       "      <td>False</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-03</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-07-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35.694003</td>\n",
       "      <td>139.753595</td>\n",
       "      <td>tokyo__tokyo-kana__tonokyo</td>\n",
       "      <td>35.691667</td>\n",
       "      <td>139.75</td>\n",
       "      <td>0.416011</td>\n",
       "      <td>0.415906</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-04</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-07-04</td>\n",
       "      <td>20.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Monday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35.694003</td>\n",
       "      <td>139.753595</td>\n",
       "      <td>tokyo__tokyo-kana__tonokyo</td>\n",
       "      <td>35.691667</td>\n",
       "      <td>139.75</td>\n",
       "      <td>0.416011</td>\n",
       "      <td>0.415906</td>\n",
       "      <td>False</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.044522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-05</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-07-05</td>\n",
       "      <td>25.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35.694003</td>\n",
       "      <td>139.753595</td>\n",
       "      <td>tokyo__tokyo-kana__tonokyo</td>\n",
       "      <td>35.691667</td>\n",
       "      <td>139.75</td>\n",
       "      <td>0.416011</td>\n",
       "      <td>0.415906</td>\n",
       "      <td>False</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.258097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    air_store_id  is_test  test_number visit_date  visitors  \\\n",
       "visit_date                                                                    \n",
       "2016-07-01  air_00a91d42b08b08d9    False          NaN 2016-07-01      35.0   \n",
       "2016-07-02  air_00a91d42b08b08d9    False          NaN 2016-07-02       9.0   \n",
       "2016-07-03  air_00a91d42b08b08d9    False          NaN 2016-07-03       0.0   \n",
       "2016-07-04  air_00a91d42b08b08d9    False          NaN 2016-07-04      20.0   \n",
       "2016-07-05  air_00a91d42b08b08d9    False          NaN 2016-07-05      25.0   \n",
       "\n",
       "           was_nil day_of_week  is_holiday  prev_day_is_holiday  \\\n",
       "visit_date                                                        \n",
       "2016-07-01   False      Friday           0                  0.0   \n",
       "2016-07-02   False    Saturday           0                  0.0   \n",
       "2016-07-03    True      Sunday           0                  0.0   \n",
       "2016-07-04   False      Monday           0                  0.0   \n",
       "2016-07-05   False     Tuesday           0                  0.0   \n",
       "\n",
       "            next_day_is_holiday          ...             latitude   longitude  \\\n",
       "visit_date                               ...                                    \n",
       "2016-07-01                  0.0          ...            35.694003  139.753595   \n",
       "2016-07-02                  0.0          ...            35.694003  139.753595   \n",
       "2016-07-03                  0.0          ...            35.694003  139.753595   \n",
       "2016-07-04                  0.0          ...            35.694003  139.753595   \n",
       "2016-07-05                  0.0          ...            35.694003  139.753595   \n",
       "\n",
       "                            station_id  station_latitude station_longitude  \\\n",
       "visit_date                                                                   \n",
       "2016-07-01  tokyo__tokyo-kana__tonokyo         35.691667            139.75   \n",
       "2016-07-02  tokyo__tokyo-kana__tonokyo         35.691667            139.75   \n",
       "2016-07-03  tokyo__tokyo-kana__tonokyo         35.691667            139.75   \n",
       "2016-07-04  tokyo__tokyo-kana__tonokyo         35.691667            139.75   \n",
       "2016-07-05  tokyo__tokyo-kana__tonokyo         35.691667            139.75   \n",
       "\n",
       "            station_vincenty  station_great_circle  is_outlier  \\\n",
       "visit_date                                                       \n",
       "2016-07-01          0.416011              0.415906       False   \n",
       "2016-07-02          0.416011              0.415906       False   \n",
       "2016-07-03          0.416011              0.415906       False   \n",
       "2016-07-04          0.416011              0.415906       False   \n",
       "2016-07-05          0.416011              0.415906       False   \n",
       "\n",
       "            visitors_capped  visitors_capped_log1p  \n",
       "visit_date                                          \n",
       "2016-07-01             35.0               3.583519  \n",
       "2016-07-02              9.0               2.302585  \n",
       "2016-07-03              0.0               0.000000  \n",
       "2016-07-04             20.0               3.044522  \n",
       "2016-07-05             25.0               3.258097  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_outliers(series):\n",
    "    return (series - series.mean()) > 2.4 * series.std()\n",
    "\n",
    "\n",
    "def cap_values(series):\n",
    "    outliers = find_outliers(series)\n",
    "    max_val = series[~outliers].max()\n",
    "    series[outliers] = max_val\n",
    "    return series\n",
    "\n",
    "\n",
    "stores = data.groupby('air_store_id')\n",
    "data['is_outlier'] = stores.apply(lambda g: find_outliers(g['visitors'])).values\n",
    "data['visitors_capped'] = stores.apply(lambda g: cap_values(g['visitors'])).values\n",
    "data['visitors_capped_log1p'] = np.log1p(data['visitors_capped'])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I extracted some simple features. The day of the month feature is quite interesting because it can be seen as a proxy of when people get paid in the month, supposing they get paid on a monthly basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['is_weekend'] = data['day_of_week'].isin(['Saturday', 'Sunday']).astype(int)\n",
    "data['day_of_month'] = data['visit_date'].dt.day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The following code block is probably the most important part of this notebook**. Exponentially weighted means (EWM) are a very way to capture the trend of a timeseries. However they rely on a paramater `alpha` which models the weighting of the mean. For example if `alpha` is close to 1 then recent values are more weighted then older ones. Choosing `alpha` is very important and there is no obvious way to choose it. I decided to do an optimization procedure to determine the best `alpha` for each store's timeseries, per day of the week.\n",
    "\n",
    "The optimization is done with [differential evolution](https://www.wikiwand.com/en/Differential_evolution). The main reason why I chose this method is that it ensures that the search space is limited between 0 and 1 (the domain of `alpha`). The objective function is the mean squared error between the timeseries and it's EWM. The EWM is computed on the timeseries shifted by 1 to make sure that the EWM can't \"look\" at the current value (else it won't work on the test set). As for how on the test, the values will be the same for the first week as well as the second, the third, etc. Of course this isn't ideal, but in my opinion there is not much else that can be done.\n",
    "\n",
    "One important thing is that I applied the following procedure per store and per day of the week but also per store and per weekend. The latter is less granular and is helpful for timeseries with not much information. Also we apply the procedure to the capped visitor information (calculated previously) and to it's logarithm. The reason why I'm doing this for the logarithm is that it smooths the timeseries and can help a bit. Variety is the spice of life."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>is_test</th>\n",
       "      <th>test_number</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>visitors</th>\n",
       "      <th>was_nil</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>prev_day_is_holiday</th>\n",
       "      <th>next_day_is_holiday</th>\n",
       "      <th>...</th>\n",
       "      <th>station_great_circle</th>\n",
       "      <th>is_outlier</th>\n",
       "      <th>visitors_capped</th>\n",
       "      <th>visitors_capped_log1p</th>\n",
       "      <th>optimized_ewm_by_air_store_id_&amp;_day_of_week</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>optimized_ewm_by_air_store_id_&amp;_is_weekend</th>\n",
       "      <th>optimized_ewm_log1p_by_air_store_id_&amp;_day_of_week</th>\n",
       "      <th>optimized_ewm_log1p_by_air_store_id_&amp;_is_weekend</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visit_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-07-01</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>35.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.415906</td>\n",
       "      <td>False</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3.583519</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-02</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-07-02</td>\n",
       "      <td>9.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.415906</td>\n",
       "      <td>False</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-03</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-07-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.415906</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-04</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-07-04</td>\n",
       "      <td>20.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Monday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.415906</td>\n",
       "      <td>False</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.583519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-05</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-07-05</td>\n",
       "      <td>25.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.415906</td>\n",
       "      <td>False</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.258097</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>33.554228</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.429215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    air_store_id  is_test  test_number visit_date  visitors  \\\n",
       "visit_date                                                                    \n",
       "2016-07-01  air_00a91d42b08b08d9    False          NaN 2016-07-01      35.0   \n",
       "2016-07-02  air_00a91d42b08b08d9    False          NaN 2016-07-02       9.0   \n",
       "2016-07-03  air_00a91d42b08b08d9    False          NaN 2016-07-03       0.0   \n",
       "2016-07-04  air_00a91d42b08b08d9    False          NaN 2016-07-04      20.0   \n",
       "2016-07-05  air_00a91d42b08b08d9    False          NaN 2016-07-05      25.0   \n",
       "\n",
       "           was_nil day_of_week  is_holiday  prev_day_is_holiday  \\\n",
       "visit_date                                                        \n",
       "2016-07-01   False      Friday           0                  0.0   \n",
       "2016-07-02   False    Saturday           0                  0.0   \n",
       "2016-07-03    True      Sunday           0                  0.0   \n",
       "2016-07-04   False      Monday           0                  0.0   \n",
       "2016-07-05   False     Tuesday           0                  0.0   \n",
       "\n",
       "            next_day_is_holiday  \\\n",
       "visit_date                        \n",
       "2016-07-01                  0.0   \n",
       "2016-07-02                  0.0   \n",
       "2016-07-03                  0.0   \n",
       "2016-07-04                  0.0   \n",
       "2016-07-05                  0.0   \n",
       "\n",
       "                                  ...                         \\\n",
       "visit_date                        ...                          \n",
       "2016-07-01                        ...                          \n",
       "2016-07-02                        ...                          \n",
       "2016-07-03                        ...                          \n",
       "2016-07-04                        ...                          \n",
       "2016-07-05                        ...                          \n",
       "\n",
       "           station_great_circle is_outlier  visitors_capped  \\\n",
       "visit_date                                                    \n",
       "2016-07-01             0.415906      False             35.0   \n",
       "2016-07-02             0.415906      False              9.0   \n",
       "2016-07-03             0.415906      False              0.0   \n",
       "2016-07-04             0.415906      False             20.0   \n",
       "2016-07-05             0.415906      False             25.0   \n",
       "\n",
       "            visitors_capped_log1p optimized_ewm_by_air_store_id_&_day_of_week  \\\n",
       "visit_date                                                                      \n",
       "2016-07-01               3.583519                                         NaN   \n",
       "2016-07-02               2.302585                                         NaN   \n",
       "2016-07-03               0.000000                                         NaN   \n",
       "2016-07-04               3.044522                                         NaN   \n",
       "2016-07-05               3.258097                                         NaN   \n",
       "\n",
       "            is_weekend  day_of_month  \\\n",
       "visit_date                             \n",
       "2016-07-01           0             1   \n",
       "2016-07-02           1             2   \n",
       "2016-07-03           1             3   \n",
       "2016-07-04           0             4   \n",
       "2016-07-05           0             5   \n",
       "\n",
       "            optimized_ewm_by_air_store_id_&_is_weekend  \\\n",
       "visit_date                                               \n",
       "2016-07-01                                         NaN   \n",
       "2016-07-02                                         NaN   \n",
       "2016-07-03                                    9.000000   \n",
       "2016-07-04                                   35.000000   \n",
       "2016-07-05                                   33.554228   \n",
       "\n",
       "            optimized_ewm_log1p_by_air_store_id_&_day_of_week  \\\n",
       "visit_date                                                      \n",
       "2016-07-01                                                NaN   \n",
       "2016-07-02                                                NaN   \n",
       "2016-07-03                                                NaN   \n",
       "2016-07-04                                                NaN   \n",
       "2016-07-05                                                NaN   \n",
       "\n",
       "            optimized_ewm_log1p_by_air_store_id_&_is_weekend  \n",
       "visit_date                                                    \n",
       "2016-07-01                                               NaN  \n",
       "2016-07-02                                               NaN  \n",
       "2016-07-03                                          2.302585  \n",
       "2016-07-04                                          3.583519  \n",
       "2016-07-05                                          3.429215  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import optimize\n",
    "\n",
    "\n",
    "def calc_shifted_ewm(series, alpha, adjust=True):\n",
    "    return series.shift().ewm(alpha=alpha, adjust=adjust).mean()\n",
    "\n",
    "\n",
    "def find_best_signal(series, adjust=False, eps=10e-5):\n",
    "    \n",
    "    def f(alpha):\n",
    "        shifted_ewm = calc_shifted_ewm(series=series, alpha=min(max(alpha, 0), 1), adjust=adjust)\n",
    "        corr = np.mean(np.power(series - shifted_ewm, 2))\n",
    "        return corr\n",
    "     \n",
    "    res = optimize.differential_evolution(func=f, bounds=[(0 + eps, 1 - eps)])\n",
    "    \n",
    "    return calc_shifted_ewm(series=series, alpha=res['x'][0], adjust=adjust)\n",
    "\n",
    "\n",
    "roll = data.groupby(['air_store_id', 'day_of_week']).apply(lambda g: find_best_signal(g['visitors_capped']))\n",
    "data['optimized_ewm_by_air_store_id_&_day_of_week'] = roll.sort_index(level=['air_store_id', 'visit_date']).values\n",
    "\n",
    "roll = data.groupby(['air_store_id', 'is_weekend']).apply(lambda g: find_best_signal(g['visitors_capped']))\n",
    "data['optimized_ewm_by_air_store_id_&_is_weekend'] = roll.sort_index(level=['air_store_id', 'visit_date']).values\n",
    "\n",
    "roll = data.groupby(['air_store_id', 'day_of_week']).apply(lambda g: find_best_signal(g['visitors_capped_log1p']))\n",
    "data['optimized_ewm_log1p_by_air_store_id_&_day_of_week'] = roll.sort_index(level=['air_store_id', 'visit_date']).values\n",
    "\n",
    "roll = data.groupby(['air_store_id', 'is_weekend']).apply(lambda g: find_best_signal(g['visitors_capped_log1p']))\n",
    "data['optimized_ewm_log1p_by_air_store_id_&_is_weekend'] = roll.sort_index(level=['air_store_id', 'visit_date']).values\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also extracted some more \"naive\" rolling features. I calculated the mean, median, standard deviation, number of values, minimum, maximum, and EWM with fixed a `alpha` parameter per timeseries. Because it's always the same I put all the logic inside a function and made the most of pandas's `groupby` and `apply`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>is_test</th>\n",
       "      <th>test_number</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>visitors</th>\n",
       "      <th>was_nil</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>prev_day_is_holiday</th>\n",
       "      <th>next_day_is_holiday</th>\n",
       "      <th>...</th>\n",
       "      <th>visitors_capped_log1p_median_by_air_store_id</th>\n",
       "      <th>visitors_capped_log1p_std_by_air_store_id</th>\n",
       "      <th>visitors_capped_log1p_count_by_air_store_id</th>\n",
       "      <th>visitors_capped_log1p_max_by_air_store_id</th>\n",
       "      <th>visitors_capped_log1p_min_by_air_store_id</th>\n",
       "      <th>visitors_capped_log1p_exp_0.1_mean_by_air_store_id</th>\n",
       "      <th>visitors_capped_log1p_exp_0.25_mean_by_air_store_id</th>\n",
       "      <th>visitors_capped_log1p_exp_0.3_mean_by_air_store_id</th>\n",
       "      <th>visitors_capped_log1p_exp_0.5_mean_by_air_store_id</th>\n",
       "      <th>visitors_capped_log1p_exp_0.75_mean_by_air_store_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visit_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-07-01</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>35.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-02</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-07-02</td>\n",
       "      <td>9.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.583519</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.583519</td>\n",
       "      <td>3.583519</td>\n",
       "      <td>3.583519</td>\n",
       "      <td>3.583519</td>\n",
       "      <td>3.583519</td>\n",
       "      <td>3.583519</td>\n",
       "      <td>3.583519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-03</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-07-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.943052</td>\n",
       "      <td>0.905757</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.583519</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>3.455426</td>\n",
       "      <td>3.263285</td>\n",
       "      <td>3.199239</td>\n",
       "      <td>2.943052</td>\n",
       "      <td>2.622819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-04</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-07-04</td>\n",
       "      <td>20.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Monday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>1.815870</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.583519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.109883</td>\n",
       "      <td>2.447464</td>\n",
       "      <td>2.239467</td>\n",
       "      <td>1.471526</td>\n",
       "      <td>0.655705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-05</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-07-05</td>\n",
       "      <td>25.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.673554</td>\n",
       "      <td>1.578354</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.583519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.103347</td>\n",
       "      <td>2.596729</td>\n",
       "      <td>2.480984</td>\n",
       "      <td>2.258024</td>\n",
       "      <td>2.447318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    air_store_id  is_test  test_number visit_date  visitors  \\\n",
       "visit_date                                                                    \n",
       "2016-07-01  air_00a91d42b08b08d9    False          NaN 2016-07-01      35.0   \n",
       "2016-07-02  air_00a91d42b08b08d9    False          NaN 2016-07-02       9.0   \n",
       "2016-07-03  air_00a91d42b08b08d9    False          NaN 2016-07-03       0.0   \n",
       "2016-07-04  air_00a91d42b08b08d9    False          NaN 2016-07-04      20.0   \n",
       "2016-07-05  air_00a91d42b08b08d9    False          NaN 2016-07-05      25.0   \n",
       "\n",
       "           was_nil day_of_week  is_holiday  prev_day_is_holiday  \\\n",
       "visit_date                                                        \n",
       "2016-07-01   False      Friday           0                  0.0   \n",
       "2016-07-02   False    Saturday           0                  0.0   \n",
       "2016-07-03    True      Sunday           0                  0.0   \n",
       "2016-07-04   False      Monday           0                  0.0   \n",
       "2016-07-05   False     Tuesday           0                  0.0   \n",
       "\n",
       "            next_day_is_holiday  \\\n",
       "visit_date                        \n",
       "2016-07-01                  0.0   \n",
       "2016-07-02                  0.0   \n",
       "2016-07-03                  0.0   \n",
       "2016-07-04                  0.0   \n",
       "2016-07-05                  0.0   \n",
       "\n",
       "                                   ...                           \\\n",
       "visit_date                         ...                            \n",
       "2016-07-01                         ...                            \n",
       "2016-07-02                         ...                            \n",
       "2016-07-03                         ...                            \n",
       "2016-07-04                         ...                            \n",
       "2016-07-05                         ...                            \n",
       "\n",
       "           visitors_capped_log1p_median_by_air_store_id  \\\n",
       "visit_date                                                \n",
       "2016-07-01                                          NaN   \n",
       "2016-07-02                                     3.583519   \n",
       "2016-07-03                                     2.943052   \n",
       "2016-07-04                                     2.302585   \n",
       "2016-07-05                                     2.673554   \n",
       "\n",
       "           visitors_capped_log1p_std_by_air_store_id  \\\n",
       "visit_date                                             \n",
       "2016-07-01                                       NaN   \n",
       "2016-07-02                                       NaN   \n",
       "2016-07-03                                  0.905757   \n",
       "2016-07-04                                  1.815870   \n",
       "2016-07-05                                  1.578354   \n",
       "\n",
       "            visitors_capped_log1p_count_by_air_store_id  \\\n",
       "visit_date                                                \n",
       "2016-07-01                                          0.0   \n",
       "2016-07-02                                          1.0   \n",
       "2016-07-03                                          2.0   \n",
       "2016-07-04                                          3.0   \n",
       "2016-07-05                                          4.0   \n",
       "\n",
       "            visitors_capped_log1p_max_by_air_store_id  \\\n",
       "visit_date                                              \n",
       "2016-07-01                                        NaN   \n",
       "2016-07-02                                   3.583519   \n",
       "2016-07-03                                   3.583519   \n",
       "2016-07-04                                   3.583519   \n",
       "2016-07-05                                   3.583519   \n",
       "\n",
       "           visitors_capped_log1p_min_by_air_store_id  \\\n",
       "visit_date                                             \n",
       "2016-07-01                                       NaN   \n",
       "2016-07-02                                  3.583519   \n",
       "2016-07-03                                  2.302585   \n",
       "2016-07-04                                  0.000000   \n",
       "2016-07-05                                  0.000000   \n",
       "\n",
       "            visitors_capped_log1p_exp_0.1_mean_by_air_store_id  \\\n",
       "visit_date                                                       \n",
       "2016-07-01                                                NaN    \n",
       "2016-07-02                                           3.583519    \n",
       "2016-07-03                                           3.455426    \n",
       "2016-07-04                                           3.109883    \n",
       "2016-07-05                                           3.103347    \n",
       "\n",
       "            visitors_capped_log1p_exp_0.25_mean_by_air_store_id  \\\n",
       "visit_date                                                        \n",
       "2016-07-01                                                NaN     \n",
       "2016-07-02                                           3.583519     \n",
       "2016-07-03                                           3.263285     \n",
       "2016-07-04                                           2.447464     \n",
       "2016-07-05                                           2.596729     \n",
       "\n",
       "            visitors_capped_log1p_exp_0.3_mean_by_air_store_id  \\\n",
       "visit_date                                                       \n",
       "2016-07-01                                                NaN    \n",
       "2016-07-02                                           3.583519    \n",
       "2016-07-03                                           3.199239    \n",
       "2016-07-04                                           2.239467    \n",
       "2016-07-05                                           2.480984    \n",
       "\n",
       "            visitors_capped_log1p_exp_0.5_mean_by_air_store_id  \\\n",
       "visit_date                                                       \n",
       "2016-07-01                                                NaN    \n",
       "2016-07-02                                           3.583519    \n",
       "2016-07-03                                           2.943052    \n",
       "2016-07-04                                           1.471526    \n",
       "2016-07-05                                           2.258024    \n",
       "\n",
       "            visitors_capped_log1p_exp_0.75_mean_by_air_store_id  \n",
       "visit_date                                                       \n",
       "2016-07-01                                                NaN    \n",
       "2016-07-02                                           3.583519    \n",
       "2016-07-03                                           2.622819    \n",
       "2016-07-04                                           0.655705    \n",
       "2016-07-05                                           2.447318    \n",
       "\n",
       "[5 rows x 94 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_precedent_statistics(df, on, group_by):\n",
    "    \n",
    "    df.sort_values(group_by + ['visit_date'], inplace=True)\n",
    "    \n",
    "    groups = df.groupby(group_by, sort=False)\n",
    "    \n",
    "    stats = {\n",
    "        'mean': [],\n",
    "        'median': [],\n",
    "        'std': [],\n",
    "        'count': [],\n",
    "        'max': [],\n",
    "        'min': []\n",
    "    }\n",
    "    \n",
    "    exp_alphas = [0.1, 0.25, 0.3, 0.5, 0.75]\n",
    "    stats.update({'exp_{}_mean'.format(alpha): [] for alpha in exp_alphas})\n",
    "    \n",
    "    for _, group in groups:\n",
    "        \n",
    "        shift = group[on].shift()\n",
    "        roll = shift.rolling(window=len(group), min_periods=1)\n",
    "        \n",
    "        stats['mean'].extend(roll.mean())\n",
    "        stats['median'].extend(roll.median())\n",
    "        stats['std'].extend(roll.std())\n",
    "        stats['count'].extend(roll.count())\n",
    "        stats['max'].extend(roll.max())\n",
    "        stats['min'].extend(roll.min())\n",
    "        \n",
    "        for alpha in exp_alphas:\n",
    "            exp = shift.ewm(alpha=alpha, adjust=False)\n",
    "            stats['exp_{}_mean'.format(alpha)].extend(exp.mean())\n",
    "    \n",
    "    suffix = '_&_'.join(group_by)\n",
    "    \n",
    "    for stat_name, values in stats.items():\n",
    "        df['{}_{}_by_{}'.format(on, stat_name, suffix)] = values\n",
    "\n",
    "\n",
    "extract_precedent_statistics(\n",
    "    df=data,\n",
    "    on='visitors_capped',\n",
    "    group_by=['air_store_id', 'day_of_week']\n",
    ")\n",
    "\n",
    "extract_precedent_statistics(\n",
    "    df=data,\n",
    "    on='visitors_capped',\n",
    "    group_by=['air_store_id', 'is_weekend']\n",
    ")\n",
    "\n",
    "extract_precedent_statistics(\n",
    "    df=data,\n",
    "    on='visitors_capped',\n",
    "    group_by=['air_store_id']\n",
    ")\n",
    "\n",
    "extract_precedent_statistics(\n",
    "    df=data,\n",
    "    on='visitors_capped_log1p',\n",
    "    group_by=['air_store_id', 'day_of_week']\n",
    ")\n",
    "\n",
    "extract_precedent_statistics(\n",
    "    df=data,\n",
    "    on='visitors_capped_log1p',\n",
    "    group_by=['air_store_id', 'is_weekend']\n",
    ")\n",
    "\n",
    "extract_precedent_statistics(\n",
    "    df=data,\n",
    "    on='visitors_capped_log1p',\n",
    "    group_by=['air_store_id']\n",
    ")\n",
    "\n",
    "data.sort_values(['air_store_id', 'visit_date']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to go with boosting in the end so the categorical variables have to be one-hot encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data, columns=['day_of_week', 'air_genre_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/test split\n",
    "\n",
    "Now let's define the training and sets so that we can train a model. A few columns in the dataset have to be dropped because they are useless. I went for predicting the log of the visitors. During prediction I also predict the log of the visitors, to get back to the original magnitude I simply apply the exponential function to the prediction. This works because $exp(log(x)) = x$. I'm pretty sure anyone serious did this during the competition. I'm not sure why this works theoretically. My intuition tells me that it helps a decision tree to pack values in a leaf because the values are \"closer\" to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['visitors_log1p'] = np.log1p(data['visitors'])\n",
    "train = data[(data['is_test'] == False) & (data['is_outlier'] == False) & (data['was_nil'] == False)]\n",
    "test = data[data['is_test']].sort_values('test_number')\n",
    "\n",
    "to_drop = ['air_store_id', 'is_test', 'test_number', 'visit_date', 'was_nil',\n",
    "           'is_outlier', 'visitors_capped', 'visitors', 'air_area_name',\n",
    "           'station_id', 'station_latitude', 'station_longitude', 'station_vincenty',\n",
    "           'station_great_circle', 'visitors_capped_log1p']\n",
    "train = train.drop(to_drop, axis='columns')\n",
    "train = train.dropna()\n",
    "test = test.drop(to_drop, axis='columns')\n",
    "\n",
    "X_train = train.drop('visitors_log1p', axis='columns')\n",
    "X_test = test.drop('visitors_log1p', axis='columns')\n",
    "y_train = train['visitors_log1p']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block just does a few sanity checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert X_train.isnull().sum().sum() == 0\n",
    "assert y_train.isnull().sum() == 0\n",
    "assert len(X_train) == len(y_train)\n",
    "assert X_test.isnull().sum().sum() == 0\n",
    "assert len(X_test) == 32019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let's do the actual machine learning. I went for a LightGVM cross-validation where I train 6 models on a random sample of the dataset. The sampling is done without replacement so technically this is known as *pasting*. I like doing parameter tuning myself and I don't use grid-search techniques as I find there are too burdensome. This is pretty classic stuff and isn't the most part of my notebook. A lot of Kagglers use this setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 RMSLE: 0.48486\n",
      "Fold 2 RMSLE: 0.48360\n",
      "Fold 3 RMSLE: 0.48666\n",
      "Fold 4 RMSLE: 0.48522\n",
      "Fold 5 RMSLE: 0.48259\n",
      "Fold 6 RMSLE: 0.48010\n",
      "Local RMSLE: 0.48384 (±0.00210)\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgbm\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "model = lgbm.LGBMRegressor(\n",
    "    objective='regression',\n",
    "    max_depth=5,\n",
    "    num_leaves=5 ** 2 - 1,\n",
    "    learning_rate=0.007,\n",
    "    n_estimators=30000,\n",
    "    min_child_samples=80,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=1,\n",
    "    reg_alpha=0,\n",
    "    reg_lambda=0,\n",
    "    random_state=np.random.randint(10e6)\n",
    ")\n",
    "\n",
    "n_splits = 6\n",
    "cv = model_selection.KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "val_scores = [0] * n_splits\n",
    "\n",
    "sub = submission['id'].to_frame()\n",
    "sub['visitors'] = 0\n",
    "\n",
    "feature_importances = pd.DataFrame(index=X_train.columns)\n",
    "\n",
    "for i, (fit_idx, val_idx) in enumerate(cv.split(X_train, y_train)):\n",
    "    \n",
    "    X_fit = X_train.iloc[fit_idx]\n",
    "    y_fit = y_train.iloc[fit_idx]\n",
    "    X_val = X_train.iloc[val_idx]\n",
    "    y_val = y_train.iloc[val_idx]\n",
    "    \n",
    "    model.fit(\n",
    "        X_fit,\n",
    "        y_fit,\n",
    "        eval_set=[(X_fit, y_fit), (X_val, y_val)],\n",
    "        eval_names=('fit', 'val'),\n",
    "        eval_metric='l2',\n",
    "        early_stopping_rounds=200,\n",
    "        feature_name=X_fit.columns.tolist(),\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    val_scores[i] = np.sqrt(model.best_score_['val']['l2'])\n",
    "    sub['visitors'] += model.predict(X_test, num_iteration=model.best_iteration_)\n",
    "    feature_importances[i] = model.feature_importances_\n",
    "    \n",
    "    print('Fold {} RMSLE: {:.5f}'.format(i+1, val_scores[i]))\n",
    "    \n",
    "sub['visitors'] /= n_splits\n",
    "sub['visitors'] = np.expm1(sub['visitors'])\n",
    "\n",
    "val_mean = np.mean(val_scores)\n",
    "val_std = np.std(val_scores)\n",
    "\n",
    "print('Local RMSLE: {:.5f} (±{:.5f})'.format(val_mean, val_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's save the submission. I like annotating the submission with the local score to compare it with the leaderboard score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub.to_csv('submissions/lgbm_{:.5f}_{:.5f}.csv'.format(val_mean, val_std), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the feature importances so to get a feeling of what worked well or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>day_of_month</th>\n",
       "      <td>7565</td>\n",
       "      <td>6490</td>\n",
       "      <td>7200</td>\n",
       "      <td>7041</td>\n",
       "      <td>6583</td>\n",
       "      <td>7424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visitors_capped_count_by_air_store_id_&amp;_is_weekend</th>\n",
       "      <td>7137</td>\n",
       "      <td>6101</td>\n",
       "      <td>6570</td>\n",
       "      <td>6306</td>\n",
       "      <td>6193</td>\n",
       "      <td>7160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optimized_ewm_by_air_store_id_&amp;_day_of_week</th>\n",
       "      <td>7097</td>\n",
       "      <td>6057</td>\n",
       "      <td>6338</td>\n",
       "      <td>6428</td>\n",
       "      <td>6124</td>\n",
       "      <td>7023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visitors_capped_log1p_std_by_air_store_id</th>\n",
       "      <td>6834</td>\n",
       "      <td>5766</td>\n",
       "      <td>6552</td>\n",
       "      <td>6110</td>\n",
       "      <td>5680</td>\n",
       "      <td>6651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optimized_ewm_log1p_by_air_store_id_&amp;_day_of_week</th>\n",
       "      <td>6755</td>\n",
       "      <td>5862</td>\n",
       "      <td>6476</td>\n",
       "      <td>6118</td>\n",
       "      <td>6171</td>\n",
       "      <td>7006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visitors_capped_std_by_air_store_id_&amp;_day_of_week</th>\n",
       "      <td>6662</td>\n",
       "      <td>5524</td>\n",
       "      <td>6273</td>\n",
       "      <td>5860</td>\n",
       "      <td>5582</td>\n",
       "      <td>6728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visitors_capped_log1p_std_by_air_store_id_&amp;_day_of_week</th>\n",
       "      <td>6651</td>\n",
       "      <td>5739</td>\n",
       "      <td>6575</td>\n",
       "      <td>6131</td>\n",
       "      <td>5838</td>\n",
       "      <td>7237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visitors_capped_std_by_air_store_id</th>\n",
       "      <td>6582</td>\n",
       "      <td>5873</td>\n",
       "      <td>6382</td>\n",
       "      <td>5958</td>\n",
       "      <td>5813</td>\n",
       "      <td>6795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visitors_capped_std_by_air_store_id_&amp;_is_weekend</th>\n",
       "      <td>6053</td>\n",
       "      <td>5200</td>\n",
       "      <td>5630</td>\n",
       "      <td>5385</td>\n",
       "      <td>5309</td>\n",
       "      <td>6215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visitors_capped_count_by_air_store_id</th>\n",
       "      <td>6052</td>\n",
       "      <td>4889</td>\n",
       "      <td>5589</td>\n",
       "      <td>5638</td>\n",
       "      <td>5186</td>\n",
       "      <td>6126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visitors_capped_exp_0.1_mean_by_air_store_id</th>\n",
       "      <td>5959</td>\n",
       "      <td>5168</td>\n",
       "      <td>5343</td>\n",
       "      <td>5207</td>\n",
       "      <td>5106</td>\n",
       "      <td>6046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visitors_capped_log1p_std_by_air_store_id_&amp;_is_weekend</th>\n",
       "      <td>5940</td>\n",
       "      <td>4870</td>\n",
       "      <td>5335</td>\n",
       "      <td>5304</td>\n",
       "      <td>5127</td>\n",
       "      <td>5701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <td>5940</td>\n",
       "      <td>4690</td>\n",
       "      <td>5497</td>\n",
       "      <td>5174</td>\n",
       "      <td>4716</td>\n",
       "      <td>5698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visitors_capped_max_by_air_store_id</th>\n",
       "      <td>5735</td>\n",
       "      <td>5162</td>\n",
       "      <td>5709</td>\n",
       "      <td>5381</td>\n",
       "      <td>5065</td>\n",
       "      <td>5931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optimized_ewm_by_air_store_id_&amp;_is_weekend</th>\n",
       "      <td>5593</td>\n",
       "      <td>4776</td>\n",
       "      <td>5395</td>\n",
       "      <td>4888</td>\n",
       "      <td>4784</td>\n",
       "      <td>5421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visitors_capped_exp_0.1_mean_by_air_store_id_&amp;_day_of_week</th>\n",
       "      <td>5544</td>\n",
       "      <td>4696</td>\n",
       "      <td>5160</td>\n",
       "      <td>5120</td>\n",
       "      <td>4983</td>\n",
       "      <td>5815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>5182</td>\n",
       "      <td>4293</td>\n",
       "      <td>4727</td>\n",
       "      <td>4343</td>\n",
       "      <td>4220</td>\n",
       "      <td>5033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visitors_capped_log1p_exp_0.1_mean_by_air_store_id_&amp;_day_of_week</th>\n",
       "      <td>5138</td>\n",
       "      <td>4087</td>\n",
       "      <td>4617</td>\n",
       "      <td>4416</td>\n",
       "      <td>4128</td>\n",
       "      <td>4840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visitors_capped_log1p_mean_by_air_store_id</th>\n",
       "      <td>5070</td>\n",
       "      <td>3872</td>\n",
       "      <td>4579</td>\n",
       "      <td>4315</td>\n",
       "      <td>4366</td>\n",
       "      <td>5113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visitors_capped_mean_by_air_store_id_&amp;_day_of_week</th>\n",
       "      <td>4995</td>\n",
       "      <td>4255</td>\n",
       "      <td>4610</td>\n",
       "      <td>4299</td>\n",
       "      <td>4312</td>\n",
       "      <td>5161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visitors_capped_log1p_exp_0.1_mean_by_air_store_id</th>\n",
       "      <td>4848</td>\n",
       "      <td>3616</td>\n",
       "      <td>4288</td>\n",
       "      <td>4202</td>\n",
       "      <td>3742</td>\n",
       "      <td>4680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visitors_capped_log1p_exp_0.75_mean_by_air_store_id_&amp;_day_of_week</th>\n",
       "      <td>4833</td>\n",
       "      <td>3933</td>\n",
       "      <td>4324</td>\n",
       "      <td>4172</td>\n",
       "      <td>3856</td>\n",
       "      <td>4760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visitors_capped_log1p_mean_by_air_store_id_&amp;_day_of_week</th>\n",
       "      <td>4800</td>\n",
       "      <td>4095</td>\n",
       "      <td>4493</td>\n",
       "      <td>4248</td>\n",
       "      <td>4090</td>\n",
       "      <td>4895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visitors_capped_mean_by_air_store_id</th>\n",
       "      <td>4643</td>\n",
       "      <td>3885</td>\n",
       "      <td>4353</td>\n",
       "      <td>3988</td>\n",
       "      <td>3856</td>\n",
       "      <td>4646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visitors_capped_exp_0.75_mean_by_air_store_id</th>\n",
       "      <td>4457</td>\n",
       "      <td>3501</td>\n",
       "      <td>4094</td>\n",
       "      <td>3846</td>\n",
       "      <td>3411</td>\n",
       "      <td>4546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optimized_ewm_log1p_by_air_store_id_&amp;_is_weekend</th>\n",
       "      <td>4375</td>\n",
       "      <td>3277</td>\n",
       "      <td>3979</td>\n",
       "      <td>3912</td>\n",
       "      <td>3697</td>\n",
       "      <td>4342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visitors_capped_max_by_air_store_id_&amp;_day_of_week</th>\n",
       "      <td>4313</td>\n",
       "      <td>3691</td>\n",
       "      <td>3930</td>\n",
       "      <td>3711</td>\n",
       "      <td>3819</td>\n",
       "      <td>4418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visitors_capped_exp_0.75_mean_by_air_store_id_&amp;_day_of_week</th>\n",
       "      <td>4301</td>\n",
       "      <td>3429</td>\n",
       "      <td>4061</td>\n",
       "      <td>3835</td>\n",
       "      <td>3582</td>\n",
       "      <td>4665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visitors_capped_log1p_exp_0.75_mean_by_air_store_id</th>\n",
       "      <td>4276</td>\n",
       "      <td>3505</td>\n",
       "      <td>4297</td>\n",
       "      <td>3879</td>\n",
       "      <td>3504</td>\n",
       "      <td>4477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visitors_capped_log1p_exp_0.75_mean_by_air_store_id_&amp;_is_weekend</th>\n",
       "      <td>4070</td>\n",
       "      <td>3335</td>\n",
       "      <td>3751</td>\n",
       "      <td>3527</td>\n",
       "      <td>3242</td>\n",
       "      <td>4046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visitors_capped_log1p_median_by_air_store_id</th>\n",
       "      <td>785</td>\n",
       "      <td>578</td>\n",
       "      <td>776</td>\n",
       "      <td>705</td>\n",
       "      <td>689</td>\n",
       "      <td>849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>air_genre_name_Izakaya</th>\n",
       "      <td>736</td>\n",
       "      <td>674</td>\n",
       "      <td>751</td>\n",
       "      <td>733</td>\n",
       "      <td>650</td>\n",
       "      <td>840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_of_week_Sunday</th>\n",
       "      <td>665</td>\n",
       "      <td>586</td>\n",
       "      <td>624</td>\n",
       "      <td>614</td>\n",
       "      <td>540</td>\n",
       "      <td>621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>air_genre_name_Dining bar</th>\n",
       "      <td>649</td>\n",
       "      <td>545</td>\n",
       "      <td>631</td>\n",
       "      <td>590</td>\n",
       "      <td>595</td>\n",
       "      <td>738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_weekend</th>\n",
       "      <td>586</td>\n",
       "      <td>561</td>\n",
       "      <td>631</td>\n",
       "      <td>596</td>\n",
       "      <td>597</td>\n",
       "      <td>611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_of_week_Thursday</th>\n",
       "      <td>506</td>\n",
       "      <td>444</td>\n",
       "      <td>520</td>\n",
       "      <td>465</td>\n",
       "      <td>453</td>\n",
       "      <td>539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_of_week_Tuesday</th>\n",
       "      <td>496</td>\n",
       "      <td>446</td>\n",
       "      <td>465</td>\n",
       "      <td>481</td>\n",
       "      <td>415</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>air_genre_name_Bar/Cocktail</th>\n",
       "      <td>479</td>\n",
       "      <td>438</td>\n",
       "      <td>420</td>\n",
       "      <td>438</td>\n",
       "      <td>442</td>\n",
       "      <td>506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>air_genre_name_Italian/French</th>\n",
       "      <td>317</td>\n",
       "      <td>299</td>\n",
       "      <td>301</td>\n",
       "      <td>318</td>\n",
       "      <td>280</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visitors_capped_min_by_air_store_id_&amp;_is_weekend</th>\n",
       "      <td>309</td>\n",
       "      <td>266</td>\n",
       "      <td>298</td>\n",
       "      <td>289</td>\n",
       "      <td>218</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_of_week_Wednesday</th>\n",
       "      <td>280</td>\n",
       "      <td>230</td>\n",
       "      <td>269</td>\n",
       "      <td>271</td>\n",
       "      <td>209</td>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>air_genre_name_Japanese food</th>\n",
       "      <td>262</td>\n",
       "      <td>228</td>\n",
       "      <td>265</td>\n",
       "      <td>200</td>\n",
       "      <td>209</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visitors_capped_min_by_air_store_id</th>\n",
       "      <td>255</td>\n",
       "      <td>217</td>\n",
       "      <td>246</td>\n",
       "      <td>289</td>\n",
       "      <td>164</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>air_genre_name_Yakiniku/Korean food</th>\n",
       "      <td>190</td>\n",
       "      <td>143</td>\n",
       "      <td>159</td>\n",
       "      <td>177</td>\n",
       "      <td>199</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>air_genre_name_Western food</th>\n",
       "      <td>186</td>\n",
       "      <td>158</td>\n",
       "      <td>149</td>\n",
       "      <td>202</td>\n",
       "      <td>157</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>air_genre_name_Okonomiyaki/Monja/Teppanyaki</th>\n",
       "      <td>170</td>\n",
       "      <td>137</td>\n",
       "      <td>94</td>\n",
       "      <td>114</td>\n",
       "      <td>110</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>air_genre_name_Creative cuisine</th>\n",
       "      <td>121</td>\n",
       "      <td>115</td>\n",
       "      <td>118</td>\n",
       "      <td>106</td>\n",
       "      <td>136</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>air_genre_name_Karaoke/Party</th>\n",
       "      <td>99</td>\n",
       "      <td>128</td>\n",
       "      <td>73</td>\n",
       "      <td>83</td>\n",
       "      <td>70</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>air_genre_name_Other</th>\n",
       "      <td>99</td>\n",
       "      <td>88</td>\n",
       "      <td>127</td>\n",
       "      <td>92</td>\n",
       "      <td>117</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>air_genre_name_Asian</th>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>air_genre_name_International cuisine</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visitors_capped_log1p_min_by_air_store_id</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visitors_capped_log1p_max_by_air_store_id</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visitors_capped_log1p_count_by_air_store_id</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visitors_capped_log1p_min_by_air_store_id_&amp;_is_weekend</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visitors_capped_log1p_max_by_air_store_id_&amp;_is_weekend</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visitors_capped_log1p_count_by_air_store_id_&amp;_is_weekend</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visitors_capped_log1p_max_by_air_store_id_&amp;_day_of_week</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visitors_capped_log1p_count_by_air_store_id_&amp;_day_of_week</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visitors_capped_log1p_min_by_air_store_id_&amp;_day_of_week</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       0     1     2     3  \\\n",
       "day_of_month                                        7565  6490  7200  7041   \n",
       "visitors_capped_count_by_air_store_id_&_is_weekend  7137  6101  6570  6306   \n",
       "optimized_ewm_by_air_store_id_&_day_of_week         7097  6057  6338  6428   \n",
       "visitors_capped_log1p_std_by_air_store_id           6834  5766  6552  6110   \n",
       "optimized_ewm_log1p_by_air_store_id_&_day_of_week   6755  5862  6476  6118   \n",
       "visitors_capped_std_by_air_store_id_&_day_of_week   6662  5524  6273  5860   \n",
       "visitors_capped_log1p_std_by_air_store_id_&_day...  6651  5739  6575  6131   \n",
       "visitors_capped_std_by_air_store_id                 6582  5873  6382  5958   \n",
       "visitors_capped_std_by_air_store_id_&_is_weekend    6053  5200  5630  5385   \n",
       "visitors_capped_count_by_air_store_id               6052  4889  5589  5638   \n",
       "visitors_capped_exp_0.1_mean_by_air_store_id        5959  5168  5343  5207   \n",
       "visitors_capped_log1p_std_by_air_store_id_&_is_...  5940  4870  5335  5304   \n",
       "latitude                                            5940  4690  5497  5174   \n",
       "visitors_capped_max_by_air_store_id                 5735  5162  5709  5381   \n",
       "optimized_ewm_by_air_store_id_&_is_weekend          5593  4776  5395  4888   \n",
       "visitors_capped_exp_0.1_mean_by_air_store_id_&_...  5544  4696  5160  5120   \n",
       "longitude                                           5182  4293  4727  4343   \n",
       "visitors_capped_log1p_exp_0.1_mean_by_air_store...  5138  4087  4617  4416   \n",
       "visitors_capped_log1p_mean_by_air_store_id          5070  3872  4579  4315   \n",
       "visitors_capped_mean_by_air_store_id_&_day_of_week  4995  4255  4610  4299   \n",
       "visitors_capped_log1p_exp_0.1_mean_by_air_store_id  4848  3616  4288  4202   \n",
       "visitors_capped_log1p_exp_0.75_mean_by_air_stor...  4833  3933  4324  4172   \n",
       "visitors_capped_log1p_mean_by_air_store_id_&_da...  4800  4095  4493  4248   \n",
       "visitors_capped_mean_by_air_store_id                4643  3885  4353  3988   \n",
       "visitors_capped_exp_0.75_mean_by_air_store_id       4457  3501  4094  3846   \n",
       "optimized_ewm_log1p_by_air_store_id_&_is_weekend    4375  3277  3979  3912   \n",
       "visitors_capped_max_by_air_store_id_&_day_of_week   4313  3691  3930  3711   \n",
       "visitors_capped_exp_0.75_mean_by_air_store_id_&...  4301  3429  4061  3835   \n",
       "visitors_capped_log1p_exp_0.75_mean_by_air_stor...  4276  3505  4297  3879   \n",
       "visitors_capped_log1p_exp_0.75_mean_by_air_stor...  4070  3335  3751  3527   \n",
       "...                                                  ...   ...   ...   ...   \n",
       "visitors_capped_log1p_median_by_air_store_id         785   578   776   705   \n",
       "air_genre_name_Izakaya                               736   674   751   733   \n",
       "day_of_week_Sunday                                   665   586   624   614   \n",
       "air_genre_name_Dining bar                            649   545   631   590   \n",
       "is_weekend                                           586   561   631   596   \n",
       "day_of_week_Thursday                                 506   444   520   465   \n",
       "day_of_week_Tuesday                                  496   446   465   481   \n",
       "air_genre_name_Bar/Cocktail                          479   438   420   438   \n",
       "air_genre_name_Italian/French                        317   299   301   318   \n",
       "visitors_capped_min_by_air_store_id_&_is_weekend     309   266   298   289   \n",
       "day_of_week_Wednesday                                280   230   269   271   \n",
       "air_genre_name_Japanese food                         262   228   265   200   \n",
       "visitors_capped_min_by_air_store_id                  255   217   246   289   \n",
       "air_genre_name_Yakiniku/Korean food                  190   143   159   177   \n",
       "air_genre_name_Western food                          186   158   149   202   \n",
       "air_genre_name_Okonomiyaki/Monja/Teppanyaki          170   137    94   114   \n",
       "air_genre_name_Creative cuisine                      121   115   118   106   \n",
       "air_genre_name_Karaoke/Party                          99   128    73    83   \n",
       "air_genre_name_Other                                  99    88   127    92   \n",
       "air_genre_name_Asian                                  18     4     7    12   \n",
       "air_genre_name_International cuisine                   1     7    19     0   \n",
       "visitors_capped_log1p_min_by_air_store_id              0     0     0     0   \n",
       "visitors_capped_log1p_max_by_air_store_id              0     0     0     0   \n",
       "visitors_capped_log1p_count_by_air_store_id            0     0     0     0   \n",
       "visitors_capped_log1p_min_by_air_store_id_&_is_...     0     0     0     0   \n",
       "visitors_capped_log1p_max_by_air_store_id_&_is_...     0     0     0     0   \n",
       "visitors_capped_log1p_count_by_air_store_id_&_i...     0     0     0     0   \n",
       "visitors_capped_log1p_max_by_air_store_id_&_day...     0     0     0     0   \n",
       "visitors_capped_log1p_count_by_air_store_id_&_d...     0     0     0     0   \n",
       "visitors_capped_log1p_min_by_air_store_id_&_day...     0     0     0     0   \n",
       "\n",
       "                                                       4     5  \n",
       "day_of_month                                        6583  7424  \n",
       "visitors_capped_count_by_air_store_id_&_is_weekend  6193  7160  \n",
       "optimized_ewm_by_air_store_id_&_day_of_week         6124  7023  \n",
       "visitors_capped_log1p_std_by_air_store_id           5680  6651  \n",
       "optimized_ewm_log1p_by_air_store_id_&_day_of_week   6171  7006  \n",
       "visitors_capped_std_by_air_store_id_&_day_of_week   5582  6728  \n",
       "visitors_capped_log1p_std_by_air_store_id_&_day...  5838  7237  \n",
       "visitors_capped_std_by_air_store_id                 5813  6795  \n",
       "visitors_capped_std_by_air_store_id_&_is_weekend    5309  6215  \n",
       "visitors_capped_count_by_air_store_id               5186  6126  \n",
       "visitors_capped_exp_0.1_mean_by_air_store_id        5106  6046  \n",
       "visitors_capped_log1p_std_by_air_store_id_&_is_...  5127  5701  \n",
       "latitude                                            4716  5698  \n",
       "visitors_capped_max_by_air_store_id                 5065  5931  \n",
       "optimized_ewm_by_air_store_id_&_is_weekend          4784  5421  \n",
       "visitors_capped_exp_0.1_mean_by_air_store_id_&_...  4983  5815  \n",
       "longitude                                           4220  5033  \n",
       "visitors_capped_log1p_exp_0.1_mean_by_air_store...  4128  4840  \n",
       "visitors_capped_log1p_mean_by_air_store_id          4366  5113  \n",
       "visitors_capped_mean_by_air_store_id_&_day_of_week  4312  5161  \n",
       "visitors_capped_log1p_exp_0.1_mean_by_air_store_id  3742  4680  \n",
       "visitors_capped_log1p_exp_0.75_mean_by_air_stor...  3856  4760  \n",
       "visitors_capped_log1p_mean_by_air_store_id_&_da...  4090  4895  \n",
       "visitors_capped_mean_by_air_store_id                3856  4646  \n",
       "visitors_capped_exp_0.75_mean_by_air_store_id       3411  4546  \n",
       "optimized_ewm_log1p_by_air_store_id_&_is_weekend    3697  4342  \n",
       "visitors_capped_max_by_air_store_id_&_day_of_week   3819  4418  \n",
       "visitors_capped_exp_0.75_mean_by_air_store_id_&...  3582  4665  \n",
       "visitors_capped_log1p_exp_0.75_mean_by_air_stor...  3504  4477  \n",
       "visitors_capped_log1p_exp_0.75_mean_by_air_stor...  3242  4046  \n",
       "...                                                  ...   ...  \n",
       "visitors_capped_log1p_median_by_air_store_id         689   849  \n",
       "air_genre_name_Izakaya                               650   840  \n",
       "day_of_week_Sunday                                   540   621  \n",
       "air_genre_name_Dining bar                            595   738  \n",
       "is_weekend                                           597   611  \n",
       "day_of_week_Thursday                                 453   539  \n",
       "day_of_week_Tuesday                                  415   418  \n",
       "air_genre_name_Bar/Cocktail                          442   506  \n",
       "air_genre_name_Italian/French                        280   381  \n",
       "visitors_capped_min_by_air_store_id_&_is_weekend     218   258  \n",
       "day_of_week_Wednesday                                209   262  \n",
       "air_genre_name_Japanese food                         209   276  \n",
       "visitors_capped_min_by_air_store_id                  164   217  \n",
       "air_genre_name_Yakiniku/Korean food                  199   189  \n",
       "air_genre_name_Western food                          157   148  \n",
       "air_genre_name_Okonomiyaki/Monja/Teppanyaki          110   134  \n",
       "air_genre_name_Creative cuisine                      136   161  \n",
       "air_genre_name_Karaoke/Party                          70   167  \n",
       "air_genre_name_Other                                 117   100  \n",
       "air_genre_name_Asian                                   7    25  \n",
       "air_genre_name_International cuisine                   1    18  \n",
       "visitors_capped_log1p_min_by_air_store_id              0     0  \n",
       "visitors_capped_log1p_max_by_air_store_id              0     0  \n",
       "visitors_capped_log1p_count_by_air_store_id            0     0  \n",
       "visitors_capped_log1p_min_by_air_store_id_&_is_...     0     0  \n",
       "visitors_capped_log1p_max_by_air_store_id_&_is_...     0     0  \n",
       "visitors_capped_log1p_count_by_air_store_id_&_i...     0     0  \n",
       "visitors_capped_log1p_max_by_air_store_id_&_day...     0     0  \n",
       "visitors_capped_log1p_count_by_air_store_id_&_d...     0     0  \n",
       "visitors_capped_log1p_min_by_air_store_id_&_day...     0     0  \n",
       "\n",
       "[98 rows x 6 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances.sort_values(0, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all there is to it! Thanks for reading. I hope you picked up some useful stuff in this notebook. Feel free to shoot me an email at **maxhalford25@gmail.com** if you have any questions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
